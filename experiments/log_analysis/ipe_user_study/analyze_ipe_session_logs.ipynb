{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the session logs from the IPE user study\n",
    "import numpy as np\n",
    "import codecs\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import difflib\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "participant_project_settings = {\n",
    "    'P38': {\n",
    "        'BASIC': 1,\n",
    "        'QE': 2,\n",
    "        'CD': 3,\n",
    "        'IPE': 4\n",
    "    },\n",
    "    'P92': {\n",
    "        'BASIC': 2,\n",
    "        'QE': 3,\n",
    "        'CD': 4,\n",
    "        'IPE': 1\n",
    "    },\n",
    "    'P93': {\n",
    "        'BASIC': 3,\n",
    "        'QE': 4,\n",
    "        'CD': 1,\n",
    "        'IPE': 2 \n",
    "    },\n",
    "    'P94': {\n",
    "        'BASIC': 4,\n",
    "        'QE': 1,\n",
    "        'CD': 2,\n",
    "        'IPE': 3 \n",
    "    },\n",
    "    'P81': {\n",
    "        'BASIC': 1,\n",
    "        'QE': 2,\n",
    "        'CD': 4,\n",
    "        'IPE': 3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR='/home/chris/Desktop/Dropbox/projects/handycat_interactive_pe/user_study_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now make a map from participants to all of thier log files \n",
    "# Because of the way we collect logs, projects may be duplicated across multiple logfiles for a participant\n",
    "def logdir_to_participant_log_map(logdir):\n",
    "    task_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "    participant_logfiles = defaultdict(list)\n",
    "    for participant_id in os.listdir(logdir):\n",
    "        print('id: {}'.format(participant_id))\n",
    "        for item in os.listdir(os.path.join(logdir, participant_id)):\n",
    "            if item.endswith('.json'):\n",
    "                participant_logfiles[participant_id].append(os.path.join(logdir, participant_id, item))\n",
    "    \n",
    "    # parse each logfile to extract its project objects\n",
    "    nested_dict = lambda: defaultdict(nested_dict)\n",
    "    participant_logs = nested_dict()\n",
    "    broken_log_groups = defaultdict(list)\n",
    "    for p_id, logfiles in participant_logfiles.items():\n",
    "        print('parsing logs for {}'.format(p_id))\n",
    "        log_objs = [json.loads(open(f).read()) for f in logfiles]\n",
    "        print('there are {} raw logs'.format(len(logfiles)))\n",
    "        # now we need to deduplicate any projects that appear in the logs multiple times\n",
    "        for log_obj in log_objs:\n",
    "            for docname, log_entries in log_obj['document'].items():\n",
    "                # extract the setting from the name\n",
    "                # names are: `<setting>-Task-<id-letter>`\n",
    "                project_setting, _, project_identifier = docname.split('-')\n",
    "                print('docname: {}, project_setting: {}'.format(docname, project_setting))\n",
    "                project_id = task_map[project_identifier]\n",
    "                # sanity: just assert that any duplicate entries have the same number of entries\n",
    "                try:\n",
    "                    if participant_logs[p_id][project_setting]['segments'] == {}:\n",
    "                        raise KeyError\n",
    "                        \n",
    "                    prev_log = json.dumps(participant_logs[p_id][project_setting]['segments'])         \n",
    "                    current_log = json.dumps(log_entries['segments'])\n",
    "                    try:\n",
    "                        assert prev_log == current_log\n",
    "                    except AssertionError:\n",
    "                        broken_log_groups[p_id].append((prev_log, current_log))\n",
    "                        # use the longer of the two\n",
    "                        print('new len {}, old len {}'.format(len(current_log), len(prev_log)))\n",
    "\n",
    "                        if len(current_log) > len(prev_log):\n",
    "                            participant_logs[p_id][project_setting]['segments'] = log_entries['segments']\n",
    "        \n",
    "                except KeyError:\n",
    "                    participant_logs[p_id][project_setting]['segments'] = log_entries['segments']\n",
    "                \n",
    "                # note we just overwrite because duplicates are identical anyway\n",
    "                participant_logs[p_id][project_setting]['project_id'] = project_id\n",
    "\n",
    "    # assert all project types exist for all participants\n",
    "    for p_id, projects in participant_logs.items():\n",
    "        assert len(projects) == 4\n",
    "        assert set(['BASIC', 'QE', 'CD', 'IPE']) == set(projects.keys())\n",
    "       \n",
    "    return participant_logs, broken_log_groups\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: P93\n",
      "id: P81\n",
      "id: P38\n",
      "id: P94\n",
      "id: P92\n",
      "parsing logs for P93\n",
      "there are 5 raw logs\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: QE-Task-D, project_setting: QE\n",
      "docname: CD-Task-A, project_setting: CD\n",
      "docname: IPE-Task-B, project_setting: IPE\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: QE-Task-D, project_setting: QE\n",
      "docname: CD-Task-A, project_setting: CD\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "new len 39719, old len 39719\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: QE-Task-D, project_setting: QE\n",
      "parsing logs for P81\n",
      "there are 4 raw logs\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "docname: IPE-Task-C, project_setting: IPE\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "new len 17384, old len 17384\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "parsing logs for P38\n",
      "there are 2 raw logs\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: CD-Task-C, project_setting: CD\n",
      "docname: IPE-Task-D, project_setting: IPE\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "parsing logs for P94\n",
      "there are 4 raw logs\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "docname: QE-Task-A, project_setting: QE\n",
      "docname: CD-Task-B, project_setting: CD\n",
      "docname: IPE-Task-C, project_setting: IPE\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "docname: QE-Task-A, project_setting: QE\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "docname: QE-Task-A, project_setting: QE\n",
      "docname: CD-Task-B, project_setting: CD\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "new len 28759, old len 28759\n",
      "parsing logs for P92\n",
      "there are 4 raw logs\n",
      "docname: QE-Task-C, project_setting: QE\n",
      "docname: BASIC-Task-B, project_setting: BASIC\n",
      "docname: QE-Task-C, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "docname: QE-Task-C, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "docname: IPE-Task-A, project_setting: IPE\n"
     ]
    }
   ],
   "source": [
    "logs, broken_logs = logdir_to_participant_log_map(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broken_logs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add function to compare the starting value of a segment with the final value\n",
    "# see the QE score log analysis notebook\n",
    "def get_before_after_from_segments(segments):\n",
    "    ordered_segments = sorted([(int(k), v) for k,v in segments.items()], key=lambda x: x[0])\n",
    "    segment_before_after = []\n",
    "    for seg_id, events in ordered_segments:\n",
    "        action_names = [e['action'] for e in events]\n",
    "        before = u''\n",
    "        after = u''\n",
    "        if 'segment-complete' in action_names:\n",
    "            # first index of 'change-segment'\n",
    "            end_event_idx = action_names.index('segment-complete')\n",
    "            before = events[end_event_idx]['data']['previousValue']\n",
    "            after = events[end_event_idx]['data']['newValue']\n",
    "\n",
    "        segment_before_after.append((seg_id, before, after))\n",
    "\n",
    "    return segment_before_after\n",
    "\n",
    "\n",
    "# time per segment given a dict of segments \n",
    "def get_time_spent_editing(segments):\n",
    "    ordered_segments = sorted([(int(k), v) for k,v in segments.items()], key=lambda x: x[0])\n",
    "    segment_times = []\n",
    "    for seg_id, events in ordered_segments:\n",
    "        action_names = [e['action'] for e in events]\n",
    "        time_in_segment = 0\n",
    "        if 'qeScore.accept' in action_names:\n",
    "            start_event_idx = action_names.index('qeScore.accept')\n",
    "            start_event_time = events[start_event_idx]['time']\n",
    "        elif 'change-segment' in action_names:\n",
    "            start_event_idx = action_names.index('change-segment')\n",
    "            start_event_time = events[start_event_idx]['time']\n",
    "\n",
    "        if 'segment-complete' in action_names:\n",
    "            # last index of 'segment-complete'\n",
    "            end_event_idx = len(action_names) - 1 - action_names[::-1].index('segment-complete')\n",
    "            end_event_time = events[end_event_idx]['time']\n",
    "            time_in_segment = end_event_time - start_event_time\n",
    "            # convert to seconds\n",
    "            time_in_segment = time_in_segment / 1000.\n",
    "\n",
    "        segment_times.append((seg_id, time_in_segment))\n",
    "    return segment_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_segment_logs(segment_logs, action_namespace=None):\n",
    "    flat_actions = []\n",
    "    for segment_log in segment_logs:\n",
    "        for seg_id, actions in segment_log.items():\n",
    "            if action_namespace is not None:\n",
    "                actions = [a for a in actions if a['action'].split('.')[0] == action_namespace]\n",
    "            flat_actions.extend(actions)\n",
    "    return flat_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_actions_by_type(segment_logs):\n",
    "    ipe_actions = flatten_segment_logs(segment_logs, action_namespace='ipe')\n",
    "    action_counts = Counter()\n",
    "    action_counts.update([a['action'].split('.')[1] for a in ipe_actions])\n",
    "    return action_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_actions_by_setting(user_logs):\n",
    "    ipe_actions = {}\n",
    "    for setting, setting_data in user_logs.items():\n",
    "        print(setting)\n",
    "        ipe_actions[setting] = Counter([a['action'].split('.')[1]\n",
    "                                        for a in flatten_segment_logs([setting_data['segments']], \n",
    "                                                                      action_namespace='ipe')]) \n",
    "    return ipe_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_action_counts = {p_id: edit_actions_by_type([data['segments'] for setting, data in d.items()])\n",
    "                      for p_id, d in logs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "QE\n",
      "BASIC\n",
      "CD\n",
      "IPE\n"
     ]
    }
   ],
   "source": [
    "user_actions_by_setting = {p_id: edit_actions_by_setting(data) for p_id, data in logs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_users = ['P38', 'P93', 'P81']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: P38\n",
      "{\n",
      "  \"BASIC\": {\n",
      "    \"confirm\": 5,\n",
      "    \"delete\": 7,\n",
      "    \"replace\": 1\n",
      "  },\n",
      "  \"QE\": {},\n",
      "  \"CD\": {\n",
      "    \"replace\": 13,\n",
      "    \"delete\": 3\n",
      "  },\n",
      "  \"IPE\": {\n",
      "    \"replace\": 10,\n",
      "    \"delete\": 3\n",
      "  }\n",
      "}\n",
      "Total IPE actions: 42\n",
      "User ID: P93\n",
      "{\n",
      "  \"BASIC\": {\n",
      "    \"confirm\": 2,\n",
      "    \"delete\": 13,\n",
      "    \"replace\": 8,\n",
      "    \"insert\": 25\n",
      "  },\n",
      "  \"QE\": {\n",
      "    \"qe_server_response\": 51,\n",
      "    \"replace\": 12,\n",
      "    \"delete\": 13,\n",
      "    \"insert\": 12\n",
      "  },\n",
      "  \"CD\": {\n",
      "    \"replace\": 8,\n",
      "    \"cd_server_response\": 6,\n",
      "    \"insert\": 11,\n",
      "    \"delete\": 5\n",
      "  },\n",
      "  \"IPE\": {\n",
      "    \"qe_server_response\": 55,\n",
      "    \"delete\": 5,\n",
      "    \"replace\": 9,\n",
      "    \"cd_server_response\": 1,\n",
      "    \"insert\": 8\n",
      "  }\n",
      "}\n",
      "Total IPE actions: 131\n",
      "User ID: P81\n",
      "{\n",
      "  \"BASIC\": {\n",
      "    \"insert\": 2,\n",
      "    \"delete\": 6\n",
      "  },\n",
      "  \"QE\": {\n",
      "    \"qe_server_response\": 27,\n",
      "    \"delete\": 4,\n",
      "    \"replace\": 6,\n",
      "    \"insert\": 2\n",
      "  },\n",
      "  \"CD\": {\n",
      "    \"insert\": 12,\n",
      "    \"delete\": 13,\n",
      "    \"cd_server_response\": 9,\n",
      "    \"replace\": 6\n",
      "  },\n",
      "  \"IPE\": {\n",
      "    \"qe_server_response\": 29,\n",
      "    \"replace\": 4,\n",
      "    \"delete\": 5,\n",
      "    \"cd_server_response\": 5,\n",
      "    \"insert\": 2\n",
      "  }\n",
      "}\n",
      "Total IPE actions: 62\n"
     ]
    }
   ],
   "source": [
    "for good_user in good_users:\n",
    "    print('User ID: {}'.format(good_user))\n",
    "    print(json.dumps(user_actions_by_setting[good_user], indent=2))\n",
    "    total_actions = sum([c for s, a in user_actions_by_setting[good_user].items() \n",
    "                         for n, c in a.items() if 'server' not in n])\n",
    "    print('Total IPE actions: {}'.format(total_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key question: did users edit more or less when there was QE feedback available?\n",
    "# Key question: did users edit the things that QE annotated more than other things?\n",
    "#      - how to measure this?\n",
    "#      - check the token annotation -- is it OK or BAD in the original sequence?\n",
    "#      - check which tokens were (probably) removed (DEL, or SUB)\n",
    "#      - we are effectively doing sequence alignment in an edit matrix\n",
    "#      - see what the TER ops are using one of the QE scripts?\n",
    "#      - we can use get_opcodes() from difflib, or possibly get_matching_blocks()\n",
    "# https://docs.python.org/2/library/difflib.html\n",
    "\n",
    "def get_edit_distance(before, after):\n",
    "    matcher = difflib.SequenceMatcher(isjunk=None, a=before, b=after)\n",
    "    return 1. - matcher.ratio()\n",
    "\n",
    "def show_how_seqs_differ(seq1, seq2):\n",
    "    matcher = difflib.SequenceMatcher(a=seq1, b=seq2, autojunk=False)\n",
    "    return matcher.get_opcodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Avg edit distance per user per setting\n",
    "\n",
    "def edit_distance_by_setting(user_log, average=False):\n",
    "    edit_distances = {}\n",
    "    for setting, data in user_log.items():\n",
    "        before_after = get_before_after_from_segments(data['segments'])\n",
    "        # note whitespace tokenization\n",
    "        edit_distance_list = [get_edit_distance(before.split(), after.split())\n",
    "                              for idx, before, after in before_after]\n",
    "        if average:\n",
    "            edit_distances[setting] = np.mean(edit_distance_list)\n",
    "        else:\n",
    "            edit_distances[setting] = edit_distance_list\n",
    "            \n",
    "    return edit_distances\n",
    "        \n",
    "\n",
    "def edit_times_by_setting(user_log, average=False):\n",
    "    edit_times = {}\n",
    "    for setting, data in user_log.items():\n",
    "        edit_times_list = [t for idx, t in get_time_spent_editing(data['segments'])]\n",
    "        if average:\n",
    "            edit_times[setting] = np.mean(edit_times_list)\n",
    "        else:\n",
    "            edit_times[setting] = edit_times_list\n",
    "            \n",
    "    return edit_times\n",
    "\n",
    "\n",
    "def get_first_qe_response(segments):\n",
    "    \"\"\"\n",
    "    Get the initial QE annotations for each segment, this should be the first server response after the segment was opened\n",
    "    \"\"\"\n",
    "    # time per segment given a dict of segments \n",
    "    ordered_segments = sorted([(int(k), v) for k,v in segments.items()], key=lambda x: x[0])\n",
    "    qe_responses = []\n",
    "    for seg_id, events in ordered_segments:\n",
    "        \n",
    "        action_names = [e['action'] for e in events]\n",
    "        time_in_segment = 0\n",
    "        if 'ipe.qe_server_response' in action_names:\n",
    "            qe_resp_idx = action_names.index('ipe.qe_server_response')\n",
    "            \n",
    "            server_response = events[qe_resp_idx]\n",
    "            qe_responses.append(server_response)\n",
    "        else:\n",
    "            qe_responses.append(None)\n",
    "\n",
    "    return qe_responses\n",
    "\n",
    "\n",
    "def qe_responses_by_setting(user_log):\n",
    "    qe_responses = {}\n",
    "    for setting, data in user_log.items():\n",
    "        qe_responses[setting] = get_first_qe_response(data['segments'])\n",
    "            \n",
    "    return qe_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P93\n",
      "{'BASIC': 0.30849339870759296, 'QE': 0.258661215327882, 'CD': 0.13750220511056424, 'IPE': 0.19231688026837665}\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "P81\n",
      "{'BASIC': 0.06035137701804369, 'QE': 0.07656863847653322, 'CD': 0.3096939772834913, 'IPE': 0.25095324361628707}\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "Edit distance pearson: (0.6703518002604267, 1.8670986044271279e-07)\n",
      "Edit time pearson: (0.43264100253658916, 0.03076704978008224)\n",
      "UID: P93, PID: 1\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "UID: P93, PID: 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'annotation_idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-eebe5f5fbde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UID: {}, PID: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m#         print(user_qe_responses[uid][pid])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqe_response_to_word_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_qe_responses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-eebe5f5fbde5>\u001b[0m in \u001b[0;36mqe_response_to_word_annotation\u001b[0;34m(qe_responses)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# we take just the first character's annotation as the annotation for the whole span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mannotation_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotation_idxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_annotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mannotation_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m# TODO: add span here? Remember whitespace offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'annotation_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "\n",
    "#Avg edit distance per user per project\n",
    "for uid in ['P93', 'P81']:\n",
    "    print(uid)\n",
    "    print(edit_distance_by_setting(logs[uid], average=True))\n",
    "    for setting in ['BASIC', 'QE', 'CD', 'IPE']:\n",
    "        print(logs[uid][setting]['project_id'])\n",
    "        \n",
    "        \n",
    "# edit distance by segment, aligned per user\n",
    "user_edit_distances = nested_dict()\n",
    "for uid in ['P93', 'P81']:\n",
    "    edit_distances_for_uid = edit_distance_by_setting(logs[uid])\n",
    "    for setting in ['BASIC', 'QE', 'CD', 'IPE']:\n",
    "        setting_pid = logs[uid][setting]['project_id'] \n",
    "        user_edit_distances[uid][setting_pid] = edit_distances_for_uid[setting]\n",
    "\n",
    "# note here we are depending upon the projects having integer ids\n",
    "# for pid in [1,2,3,4]:\n",
    "#     edit_distances_for_project = list(zip(*[user_edit_distances[uid][pid] for uid in ['P93', 'P81']]))\n",
    "#     print('Project id: {}'.format(pid))\n",
    "#     print(json.dumps(edit_distances_for_project, indent=2))\n",
    "\n",
    "# edit times by segment, aligned per user\n",
    "user_edit_times = nested_dict()\n",
    "for uid in ['P93', 'P81']:\n",
    "    edit_times_for_uid = edit_times_by_setting(logs[uid])\n",
    "    for setting in ['BASIC', 'QE', 'CD', 'IPE']:\n",
    "        setting_pid = logs[uid][setting]['project_id'] \n",
    "        user_edit_times[uid][setting_pid] = edit_times_for_uid[setting]\n",
    "    \n",
    "# TODO: what is pearson (or spearman?) between edit distances (how well does user_1_edit predict user_2_edit?) \n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "user1_edit_distances = np.array([d for pid in [1,2,3,4] for d in user_edit_distances['P93'][pid]])\n",
    "user2_edit_distances = np.array([d for pid in [1,2,3,4] for d in user_edit_distances['P81'][pid]])\n",
    "assert len(user1_edit_distances) == len(user2_edit_distances)\n",
    "print('Edit distance pearson: {}'.format(pearsonr(user1_edit_distances, user2_edit_distances)))\n",
    "# conclusion: we make the same edits, regardless of setting \n",
    "#(0.6703518002604267, 1.8670986044271279e-07)\n",
    "    \n",
    "user1_edit_times = [d for pid in [1,2,3,4] for d in user_edit_times['P93'][pid]]\n",
    "user2_edit_times = [d for pid in [1,2,3,4] for d in user_edit_times['P81'][pid]]\n",
    "\n",
    "# disard outliers\n",
    "user_edit_time_pairs = list(zip(user1_edit_times, user2_edit_times))\n",
    "outlier_margin = 60.\n",
    "user1_edit_times, user2_edit_times = zip(*[p for p in user_edit_time_pairs if abs(p[0] - p[1] < outlier_margin)])\n",
    "user1_edit_times = list(user1_edit_times)\n",
    "user2_edit_times = list(user2_edit_times)\n",
    "\n",
    "assert len(user1_edit_times) == len(user2_edit_times)\n",
    "print('Edit time pearson: {}'.format(pearsonr(user1_edit_times, user2_edit_times)))\n",
    "\n",
    "user_qe_responses = nested_dict()\n",
    "for uid in ['P93', 'P81']:\n",
    "    qe_responses_for_uid = qe_responses_by_setting(logs[uid])\n",
    "    for setting in ['BASIC', 'QE', 'CD', 'IPE']:\n",
    "        setting_pid = logs[uid][setting]['project_id'] \n",
    "        user_qe_responses[uid][setting_pid] = qe_responses_for_uid[setting]\n",
    "        \n",
    "# print(json.dumps(user_qe_responses, indent=2))\n",
    "\n",
    "def qe_response_to_word_annotation(qe_responses):\n",
    "    \n",
    "    all_annotations = []\n",
    "    \n",
    "    # we assume whitespace tokenization, although that isn't how the model actually works\n",
    "    for resp in qe_responses:\n",
    "        if resp is None:\n",
    "            all_annotations.append(None)\n",
    "        else:\n",
    "            token_annotations = []\n",
    "            text = resp['data']['text']\n",
    "            char_annotations = sorted([(int(k), v['tag'], v['confidence']) \n",
    "                                       for k, v in resp['data']['annotations'].items()], key=lambda x: x[0])\n",
    "            annotation_idxs = [idx for idx, _, _ in char_annotations]\n",
    "            token_spans = resp['data']['spans']\n",
    "            for span in token_spans:\n",
    "                word = text[span[0]:span[1]]\n",
    "                # we take just the first character's annotation as the annotation for the whole span\n",
    "                annotation_idx = annotation_idxs.index(span[0])\n",
    "                tag = char_annotations[annotation_idx][1]\n",
    "                # TODO: add span here? Remember whitespace offset\n",
    "                token_annotations.append((word, tag))\n",
    "            all_annotations.append(token_annotations)\n",
    "            \n",
    "    return all_annotations\n",
    "\n",
    "for uid in ['P93', 'P81']:\n",
    "    for pid in [1,2,3,4]:\n",
    "        print('UID: {}, PID: {}'.format(uid, pid))\n",
    "#         print(user_qe_responses[uid][pid])\n",
    "        print(qe_response_to_word_annotation(user_qe_responses[uid][pid]))\n",
    "\n",
    "\n",
    "\n",
    "# Analysis of QE Quality\n",
    "# Idea classifier with probability p(word_will_change | word_is_annotated_as_bad)\n",
    "# Two things: (1) QE is good, (2) user trusts QE\n",
    "# if QE is good, we can test the other settings where QE was not available in the UI\n",
    "# we need a list of spans with QE labels, and a corresponding list indicating whether that span changed in the final output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 4, 1, 2, '1', '2', '3', '4'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_qe_responses['P93'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = get_before_after_from_segments(logs['P93']['BASIC']['segments'])\n",
    "seq_a, seq_b = ttt[0][1].split(), ttt[0][2].split()\n",
    "test_diff = show_how_seqs_differ(seq_a, seq_b)\n",
    "print(list(test_diff))\n",
    "for tag, i1, i2, j1, j2 in test_diff:\n",
    "    print (\"%7s a[%d:%d] (%s) b[%d:%d] (%s)\" % \n",
    "           (tag, i1, i2, seq_a[i1:i2], j1, j2, seq_b[j1:j2]))\n",
    "    \n",
    "# {'action': 'ipe.qe_server_response',\n",
    "#                 'data': {'annotations': {'10': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '12': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '13': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '14': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '16': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '17': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '18': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '20': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '21': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '22': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '24': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '25': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '26': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '27': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '28': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '29': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '30': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '31': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '32': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '33': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '34': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '35': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '37': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '38': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '39': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '4': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '40': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '41': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '42': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '43': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '44': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '45': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '46': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '47': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '48': {'confidence': 1, 'tag': 'BAD'},\n",
    "#                   '5': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '50': {'confidence': 0.3333333333333333, 'tag': 'OK'},\n",
    "#                   '51': {'confidence': 0.3333333333333333, 'tag': 'OK'},\n",
    "#                   '52': {'confidence': 0.3333333333333333, 'tag': 'OK'},\n",
    "#                   '53': {'confidence': 0.3333333333333333, 'tag': 'OK'},\n",
    "#                   '54': {'confidence': 0.3333333333333333, 'tag': 'OK'},\n",
    "#                   '56': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '57': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '59': {'confidence': 0.8333333333333334, 'tag': 'OK'},\n",
    "#                   '6': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '60': {'confidence': 0.8333333333333334, 'tag': 'OK'},\n",
    "#                   '61': {'confidence': 0.8333333333333334, 'tag': 'OK'},\n",
    "#                   '63': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '64': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '65': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '66': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '67': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '68': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '69': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '7': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '70': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '71': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '72': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '73': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '74': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '76': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '77': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '78': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '8': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '80': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '81': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '82': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '83': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '84': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '85': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '86': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '87': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '88': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '89': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '9': {'confidence': 1, 'tag': 'OK'},\n",
    "#                   '90': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '91': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '92': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '93': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '94': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '95': {'confidence': 0.9166666666666666, 'tag': 'OK'},\n",
    "#                   '96': {'confidence': 0.9166666666666666, 'tag': 'OK'}},\n",
    "#                  'spans': [[4, 11],\n",
    "#                   [12, 15],\n",
    "#                   [16, 19],\n",
    "#                   [20, 23],\n",
    "#                   [24, 36],\n",
    "#                   [37, 38],\n",
    "#                   [38, 49],\n",
    "#                   [50, 55],\n",
    "#                   [56, 58],\n",
    "#                   [59, 62],\n",
    "#                   [63, 75],\n",
    "#                   [76, 79],\n",
    "#                   [80, 96],\n",
    "#                   [96, 97]],\n",
    "#                  'text': '    Klicken Sie auf die Schaltfläche \"Nummerierte Liste in der Symbolleiste zur Textformatierung.   '},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: mean edit distance per user\n",
    "# Remember: we have a lot of segments, but just two users\n",
    "# Remember: we have the before/after segments for more than just two users\n",
    "#    - especially in the case of QE, this information could be useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs['P93']['QE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def barplot_action_types(actions_by_setting):\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    settings = ['IPE', 'CD', 'QE', 'BASIC']\n",
    "    action_types = ['insert', 'delete', 'replace']\n",
    "    action_colors = {\n",
    "        'insert': 'green',\n",
    "        'delete': 'red',\n",
    "        'replace': 'blue'\n",
    "    }\n",
    "    \n",
    "    ind = np.arange(len(actions_by_setting))\n",
    "    width = 0.2\n",
    "    \n",
    "    bar_groups = defaultdict(list)\n",
    "    # TODO: group label is setting\n",
    "    for setting in settings:\n",
    "        action_counts = actions_by_setting[setting]\n",
    "        for action in action_types:\n",
    "            if action in action_counts:\n",
    "                bar_groups[action].append(action_counts[action])\n",
    "            else:\n",
    "                bar_groups[action].append(0)\n",
    "    \n",
    "    # TODO: colored legend by action type\n",
    "    for offset, (action, counts) in enumerate(bar_groups.items()):\n",
    "        ax.barh(ind + (width*offset), counts, width, \n",
    "                color=action_colors[action], \n",
    "                edgecolor='black',\n",
    "                linewidth=1,\n",
    "                label=action)\n",
    "    \n",
    "    # Add the axis labels\n",
    "    #ax.set_ylabel(\"Editing Time (seconds)\")\n",
    "    #ax.set_xlabel(\"Sentence Id (sorted by increasing length)\")\n",
    "    ax.set(yticks=ind+(1*width),\n",
    "           yticklabels=settings,\n",
    "           ylim=[3*width - 1, len(actions_by_setting)])\n",
    "    \n",
    "    # Add a legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], loc='upper right')\n",
    "    ax.legend()\n",
    "\n",
    "barplot_action_types(user_actions_by_setting['P81'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
