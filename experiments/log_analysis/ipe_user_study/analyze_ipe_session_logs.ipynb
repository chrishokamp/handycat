{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the session logs from the IPE user study\n",
    "import numpy as np\n",
    "import codecs\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import difflib\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "participant_project_settings = {\n",
    "    'P38': {\n",
    "        'BASIC': 1,\n",
    "        'QE': 2,\n",
    "        'CD': 3,\n",
    "        'IPE': 4\n",
    "    },\n",
    "    'P92': {\n",
    "        'BASIC': 2,\n",
    "        'QE': 3,\n",
    "        'CD': 4,\n",
    "        'IPE': 1\n",
    "    },\n",
    "    'P93': {\n",
    "        'BASIC': 3,\n",
    "        'QE': 4,\n",
    "        'CD': 1,\n",
    "        'IPE': 2 \n",
    "    },\n",
    "    'P94': {\n",
    "        'BASIC': 4,\n",
    "        'QE': 1,\n",
    "        'CD': 2,\n",
    "        'IPE': 3 \n",
    "    },\n",
    "    'P81': {\n",
    "        'BASIC': 1,\n",
    "        'QE': 2,\n",
    "        'CD': 4,\n",
    "        'IPE': 3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR='/home/chris/Desktop/Dropbox/projects/handycat_interactive_pe/user_study_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now make a map from participants to all of thier log files \n",
    "# Because of the way we collect logs, projects may be duplicated across multiple logfiles for a participant\n",
    "def logdir_to_participant_log_map(logdir):\n",
    "    task_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "    participant_logfiles = defaultdict(list)\n",
    "    for participant_id in os.listdir(logdir):\n",
    "        print('id: {}'.format(participant_id))\n",
    "        for item in os.listdir(os.path.join(logdir, participant_id)):\n",
    "            if item.endswith('.json'):\n",
    "                participant_logfiles[participant_id].append(os.path.join(logdir, participant_id, item))\n",
    "    \n",
    "    # parse each logfile to extract its project objects\n",
    "    nested_dict = lambda: defaultdict(nested_dict)\n",
    "    participant_logs = nested_dict()\n",
    "    broken_log_groups = defaultdict(list)\n",
    "    for p_id, logfiles in participant_logfiles.items():\n",
    "        print('parsing logs for {}'.format(p_id))\n",
    "        log_objs = [json.loads(open(f).read()) for f in logfiles]\n",
    "        print('there are {} raw logs'.format(len(logfiles)))\n",
    "        # now we need to deduplicate any projects that appear in the logs multiple times\n",
    "        for log_obj in log_objs:\n",
    "            for docname, log_entries in log_obj['document'].items():\n",
    "                # extract the setting from the name\n",
    "                # names are: `<setting>-Task-<id-letter>`\n",
    "                project_setting, _, project_identifier = docname.split('-')\n",
    "                print('docname: {}, project_setting: {}'.format(docname, project_setting))\n",
    "                project_id = task_map[project_identifier]\n",
    "                # sanity: just assert that any duplicate entries have the same number of entries\n",
    "                try:\n",
    "                    if participant_logs[p_id][project_setting]['segments'] == {}:\n",
    "                        raise KeyError\n",
    "                        \n",
    "                    prev_log = json.dumps(participant_logs[p_id][project_setting]['segments'])         \n",
    "                    current_log = json.dumps(log_entries['segments'])\n",
    "                    try:\n",
    "                        assert prev_log == current_log\n",
    "                    except AssertionError:\n",
    "                        broken_log_groups[p_id].append((prev_log, current_log))\n",
    "                        # use the longer of the two\n",
    "                        print('new len {}, old len {}'.format(len(current_log), len(prev_log)))\n",
    "\n",
    "                        if len(current_log) > len(prev_log):\n",
    "                            participant_logs[p_id][project_setting]['segments'] = log_entries['segments']\n",
    "        \n",
    "                except KeyError:\n",
    "                    participant_logs[p_id][project_setting]['segments'] = log_entries['segments']\n",
    "                \n",
    "                # note we just overwrite because duplicates are identical anyway\n",
    "                participant_logs[p_id][project_setting]['project_id'] = project_id\n",
    "\n",
    "    # assert all project types exist for all participants\n",
    "    for p_id, projects in participant_logs.items():\n",
    "        assert len(projects) == 4\n",
    "        assert set(['BASIC', 'QE', 'CD', 'IPE']) == set(projects.keys())\n",
    "       \n",
    "    return participant_logs, broken_log_groups\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: P93\n",
      "id: P81\n",
      "id: P38\n",
      "id: P94\n",
      "id: P92\n",
      "parsing logs for P93\n",
      "there are 5 raw logs\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: QE-Task-D, project_setting: QE\n",
      "docname: CD-Task-A, project_setting: CD\n",
      "docname: IPE-Task-B, project_setting: IPE\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: QE-Task-D, project_setting: QE\n",
      "docname: CD-Task-A, project_setting: CD\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "new len 39719, old len 39719\n",
      "docname: BASIC-Task-C, project_setting: BASIC\n",
      "docname: QE-Task-D, project_setting: QE\n",
      "parsing logs for P81\n",
      "there are 4 raw logs\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "docname: IPE-Task-C, project_setting: IPE\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "new len 17384, old len 17384\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "parsing logs for P38\n",
      "there are 2 raw logs\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "docname: CD-Task-C, project_setting: CD\n",
      "docname: IPE-Task-D, project_setting: IPE\n",
      "docname: BASIC-Task-A, project_setting: BASIC\n",
      "docname: QE-Task-B, project_setting: QE\n",
      "parsing logs for P94\n",
      "there are 4 raw logs\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "docname: QE-Task-A, project_setting: QE\n",
      "docname: CD-Task-B, project_setting: CD\n",
      "docname: IPE-Task-C, project_setting: IPE\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "docname: QE-Task-A, project_setting: QE\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "docname: QE-Task-A, project_setting: QE\n",
      "docname: CD-Task-B, project_setting: CD\n",
      "docname: BASIC-Task-D, project_setting: BASIC\n",
      "new len 28759, old len 28759\n",
      "parsing logs for P92\n",
      "there are 4 raw logs\n",
      "docname: QE-Task-C, project_setting: QE\n",
      "docname: BASIC-Task-B, project_setting: BASIC\n",
      "docname: QE-Task-C, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "docname: QE-Task-C, project_setting: QE\n",
      "docname: CD-Task-D, project_setting: CD\n",
      "docname: IPE-Task-A, project_setting: IPE\n"
     ]
    }
   ],
   "source": [
    "logs, broken_logs = logdir_to_participant_log_map(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broken_logs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add function to compare the starting value of a segment with the final value\n",
    "# see the QE score log analysis notebook\n",
    "def get_before_after_from_segments(segments):\n",
    "    ordered_segments = sorted([(int(k), v) for k,v in segments.items()], key=lambda x: x[0])\n",
    "    segment_before_after = []\n",
    "    for seg_id, events in ordered_segments:\n",
    "        action_names = [e['action'] for e in events]\n",
    "        before = u''\n",
    "        after = u''\n",
    "        if 'segment-complete' in action_names:\n",
    "            # first index of 'change-segment'\n",
    "            end_event_idx = action_names.index('segment-complete')\n",
    "            before = events[end_event_idx]['data']['previousValue']\n",
    "            after = events[end_event_idx]['data']['newValue']\n",
    "\n",
    "        segment_before_after.append((seg_id, before, after))\n",
    "\n",
    "    return segment_before_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_segment_logs(segment_logs, action_namespace=None):\n",
    "    flat_actions = []\n",
    "    for segment_log in segment_logs:\n",
    "        for seg_id, actions in segment_log.items():\n",
    "            if action_namespace is not None:\n",
    "                actions = [a for a in actions if a['action'].split('.')[0] == action_namespace]\n",
    "            flat_actions.extend(actions)\n",
    "    return flat_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_actions_by_type(segment_logs):\n",
    "    ipe_actions = flatten_segment_logs(segment_logs, action_namespace='ipe')\n",
    "    action_counts = Counter()\n",
    "    action_counts.update([a['action'].split('.')[1] for a in ipe_actions])\n",
    "    return action_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_actions_by_setting(user_logs):\n",
    "    ipe_actions = {}\n",
    "    for setting, setting_data in user_logs.items():\n",
    "        print(setting)\n",
    "        ipe_actions[setting] = Counter([a['action'].split('.')[1]\n",
    "                                        for a in flatten_segment_logs([setting_data['segments']], \n",
    "                                                                      action_namespace='ipe')]) \n",
    "    return ipe_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_action_counts = {p_id: edit_actions_by_type([data['segments'] for setting, data in d.items()])\n",
    "                      for p_id, d in logs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "BASIC\n",
      "QE\n",
      "CD\n",
      "IPE\n",
      "QE\n",
      "BASIC\n",
      "CD\n",
      "IPE\n"
     ]
    }
   ],
   "source": [
    "user_actions_by_setting = {p_id: edit_actions_by_setting(data) for p_id, data in logs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_users = ['P38', 'P93', 'P81']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: P38\n",
      "{\n",
      "  \"BASIC\": {\n",
      "    \"confirm\": 5,\n",
      "    \"delete\": 7,\n",
      "    \"replace\": 1\n",
      "  },\n",
      "  \"QE\": {},\n",
      "  \"CD\": {\n",
      "    \"replace\": 13,\n",
      "    \"delete\": 3\n",
      "  },\n",
      "  \"IPE\": {\n",
      "    \"replace\": 10,\n",
      "    \"delete\": 3\n",
      "  }\n",
      "}\n",
      "Total IPE actions: 42\n",
      "User ID: P93\n",
      "{\n",
      "  \"BASIC\": {\n",
      "    \"confirm\": 2,\n",
      "    \"delete\": 13,\n",
      "    \"replace\": 8,\n",
      "    \"insert\": 25\n",
      "  },\n",
      "  \"QE\": {\n",
      "    \"qe_server_response\": 51,\n",
      "    \"replace\": 12,\n",
      "    \"delete\": 13,\n",
      "    \"insert\": 12\n",
      "  },\n",
      "  \"CD\": {\n",
      "    \"replace\": 8,\n",
      "    \"cd_server_response\": 6,\n",
      "    \"insert\": 11,\n",
      "    \"delete\": 5\n",
      "  },\n",
      "  \"IPE\": {\n",
      "    \"qe_server_response\": 55,\n",
      "    \"delete\": 5,\n",
      "    \"replace\": 9,\n",
      "    \"cd_server_response\": 1,\n",
      "    \"insert\": 8\n",
      "  }\n",
      "}\n",
      "Total IPE actions: 131\n",
      "User ID: P81\n",
      "{\n",
      "  \"BASIC\": {\n",
      "    \"insert\": 2,\n",
      "    \"delete\": 6\n",
      "  },\n",
      "  \"QE\": {\n",
      "    \"qe_server_response\": 27,\n",
      "    \"delete\": 4,\n",
      "    \"replace\": 6,\n",
      "    \"insert\": 2\n",
      "  },\n",
      "  \"CD\": {\n",
      "    \"insert\": 12,\n",
      "    \"delete\": 13,\n",
      "    \"cd_server_response\": 9,\n",
      "    \"replace\": 6\n",
      "  },\n",
      "  \"IPE\": {\n",
      "    \"qe_server_response\": 29,\n",
      "    \"replace\": 4,\n",
      "    \"delete\": 5,\n",
      "    \"cd_server_response\": 5,\n",
      "    \"insert\": 2\n",
      "  }\n",
      "}\n",
      "Total IPE actions: 62\n"
     ]
    }
   ],
   "source": [
    "for good_user in good_users:\n",
    "    print('User ID: {}'.format(good_user))\n",
    "    print(json.dumps(user_actions_by_setting[good_user], indent=2))\n",
    "    total_actions = sum([c for s, a in user_actions_by_setting[good_user].items() \n",
    "                         for n, c in a.items() if 'server' not in n])\n",
    "    print('Total IPE actions: {}'.format(total_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key question: did users edit more or less when there was QE feedback available?\n",
    "# Key question: did users edit the things that QE annotated more than other things?\n",
    "#      - how to measure this?\n",
    "#      - check the token annotation -- is it OK or BAD in the original sequence?\n",
    "#      - check which tokens were (probably) removed (DEL, or SUB)\n",
    "#      - we are effectively doing sequence alignment in an edit matrix\n",
    "#      - see what the TER ops are using one of the QE scripts?\n",
    "#      - we can use get_opcodes() from difflib, or possibly get_matching_blocks()\n",
    "# https://docs.python.org/2/library/difflib.html\n",
    "\n",
    "def get_edit_distance(before, after):\n",
    "    matcher = difflib.SequenceMatcher(isjunk=None, a=before, b=after)\n",
    "    return 1. - matcher.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_how_seqs_differ(seq1, seq2):\n",
    "    matcher = difflib.SequenceMatcher(a=seq1, b=seq2, autojunk=False)\n",
    "    return matcher.get_opcodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('equal', 0, 1, 0, 1), ('replace', 1, 2, 1, 3), ('equal', 2, 5, 3, 6), ('replace', 5, 6, 6, 7), ('equal', 6, 9, 7, 10), ('replace', 9, 10, 10, 11), ('equal', 10, 14, 11, 15)]\n",
      "  equal a[0:1] (['In']) b[0:1] (['In'])\n",
      "replace a[1:2] (['Contribute,']) b[1:3] (['Beitragen', ','])\n",
      "  equal a[2:5] (['klicken', 'Sie', 'auf']) b[3:6] (['klicken', 'Sie', 'auf'])\n",
      "replace a[5:6] (['Veröffentlichen,']) b[6:7] (['\"Veröffentlichen\",'])\n",
      "  equal a[6:9] (['um', 'die', 'Änderungen']) b[7:10] (['um', 'die', 'Änderungen'])\n",
      "replace a[9:10] (['in']) b[10:11] (['auf'])\n",
      "  equal a[10:14] (['der', 'Website', 'zu', 'veröffentlichen.']) b[11:15] (['der', 'Website', 'zu', 'veröffentlichen.'])\n"
     ]
    }
   ],
   "source": [
    "ttt = get_before_after_from_segments(logs['P93']['BASIC']['segments'])\n",
    "seq_a, seq_b = ttt[0][1].split(), ttt[0][2].split()\n",
    "test_diff = show_how_seqs_differ(seq_a, seq_b)\n",
    "print(list(test_diff))\n",
    "for tag, i1, i2, j1, j2 in test_diff:\n",
    "    print (\"%7s a[%d:%d] (%s) b[%d:%d] (%s)\" % \n",
    "           (tag, i1, i2, seq_a[i1:i2], j1, j2, seq_b[j1:j2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-acd32e7f1502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_diff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     print (\"%7s a[%d:%d] (%s) b[%d:%d] (%s)\" % \n\u001b[0;32m----> 3\u001b[0;31m            (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2]))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: mean edit distance per user\n",
    "# Remember: we have a lot of segments, but just two users\n",
    "# Remember: we have the before/after segments for more than just two users\n",
    "#    - especially in the case of QE, this information could be useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'In Contribute, klicken Sie auf Veröffentlichen, um die Änderungen in der Website zu veröffentlichen.',\n",
       "  'In Beitragen , klicken Sie auf \"Veröffentlichen\", um die Änderungen auf der Website zu veröffentlichen.'),\n",
       " (1,\n",
       "  'Der Zeiger des Innenkreises ist die Begrenzung des Werkzeugs in voller Stärke angezeigt.',\n",
       "  'Der Innenkreis des Zeigers zeigt die Begrenzung des Werkzeugs bei voller Stärke an .'),\n",
       " (2,\n",
       "  'Sie können auch die Reinigungsläsung malen Sie mit einem Airbrush simulieren.',\n",
       "  'Sie können auch Sprühfarbe mit einem Airbrush simulieren.'),\n",
       " (3,\n",
       "  'Wählen Sie das Slice-Auswahlwerkzeug aus und klicken Sie auf das Segment im Bild.',\n",
       "  'Wählen Sie das Ausschnittwerkzeug aus und klicken Sie auf das Segment im Bild.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def barplot_action_types(actions_by_setting):\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    settings = ['IPE', 'CD', 'QE', 'BASIC']\n",
    "    action_types = ['insert', 'delete', 'replace']\n",
    "    action_colors = {\n",
    "        'insert': 'green',\n",
    "        'delete': 'red',\n",
    "        'replace': 'blue'\n",
    "    }\n",
    "    \n",
    "    ind = np.arange(len(actions_by_setting))\n",
    "    width = 0.2\n",
    "    \n",
    "    bar_groups = defaultdict(list)\n",
    "    # TODO: group label is setting\n",
    "    for setting in settings:\n",
    "        action_counts = actions_by_setting[setting]\n",
    "        for action in action_types:\n",
    "            if action in action_counts:\n",
    "                bar_groups[action].append(action_counts[action])\n",
    "            else:\n",
    "                bar_groups[action].append(0)\n",
    "    \n",
    "    # TODO: colored legend by action type\n",
    "    for offset, (action, counts) in enumerate(bar_groups.items()):\n",
    "        ax.barh(ind + (width*offset), counts, width, \n",
    "                color=action_colors[action], \n",
    "                edgecolor='black',\n",
    "                linewidth=1,\n",
    "                label=action)\n",
    "    \n",
    "    # Add the axis labels\n",
    "    #ax.set_ylabel(\"Editing Time (seconds)\")\n",
    "    #ax.set_xlabel(\"Sentence Id (sorted by increasing length)\")\n",
    "    ax.set(yticks=ind+(1*width),\n",
    "           yticklabels=settings,\n",
    "           ylim=[3*width - 1, len(actions_by_setting)])\n",
    "    \n",
    "    # Add a legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], loc='upper right')\n",
    "    ax.legend()\n",
    "\n",
    "barplot_action_types(user_actions_by_setting['P81'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
