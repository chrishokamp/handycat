{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to extract segments from the WMT data according to a few criteria\n",
    "# (1) segments should be short because constrained decoding is slow\n",
    "# (2) segments should contain a minimum of special characters, numbers, and domain jargon\n",
    "# (3) segments should not match the reference (translations should require some editing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import itertools\n",
    "import sys\n",
    "import errno\n",
    "from subprocess import Popen, PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATADIR = '/media/1tb_drive/Dropbox/data/qe/wmt_2017/test/wmt17_qe_test_data/word_level/2016/'\n",
    "\n",
    "# Note we use the data with no processing applied, because we want to render as realistically as possible in the UI\n",
    "SRC_FILE = os.path.join(DATADIR, 'test.src')\n",
    "MT_FILE = os.path.join(DATADIR, 'test.mt')\n",
    "PE_FILE = os.path.join(DATADIR, 'test.pe')\n",
    "\n",
    "\n",
    "\n",
    "def parallel_iterator(src_file, mt_file, pe_file):\n",
    "    with codecs.open(src_file, encoding='utf8') as src:\n",
    "        with codecs.open(mt_file, encoding='utf8') as mt:\n",
    "            with codecs.open(pe_file, encoding='utf8') as pe:\n",
    "                for src_l, mt_l, pe_l in itertools.izip(src, mt, pe):\n",
    "                    yield (src_l.strip(), mt_l.strip(), pe_l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length_filter(min_length=None, max_length=None):\n",
    "    \"\"\"Return a filter function rejecting segments with src length > max_length\"\"\"\n",
    "    if min_length is None and max_length is None:\n",
    "        raise(AssertionError('You must define at least one of {min_length, max_length}'))\n",
    "        \n",
    "    if min_length is None:\n",
    "        min_length = 0\n",
    "    if max_length is None:\n",
    "        max_length = sys.maxint\n",
    "     \n",
    "    def filter_len(triple):\n",
    "        if min_length <= len(triple[0]) <= max_length:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return filter_len\n",
    "\n",
    "def char_filter(bad_chars):\n",
    "    \"\"\"Return a filter function rejecting segments where src sequence contains unwanted chars\"\"\"\n",
    "    def filter_chars(triple):\n",
    "        if any(char in triple[0] for char in bad_chars):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    return filter_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset output hyperparams\n",
    "OUTPUT_DIR = '/home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data'\n",
    "mkdir_p(OUTPUT_DIR)\n",
    "\n",
    "NUM_PROJECTS = 5\n",
    "SEGMENTS_PER_PROJECT = 12\n",
    "\n",
    "MIN_SEGMENT_LENGTH = 50\n",
    "MAX_SEGMENT_LENGTH = 75\n",
    "\n",
    "SRC_LANG = 'en'\n",
    "TRG_LANG = 'de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_1 = length_filter(min_length=MIN_SEGMENT_LENGTH, max_length=MAX_SEGMENT_LENGTH)\n",
    "chars_to_filter = [u'>', u'\"', u'(', u')', u'+', u'^', u'Â®', u':', u';', u'/', u'\\\\']\n",
    "chars_to_filter.extend([unicode(c) for c in range(10)])\n",
    "filter_2 = char_filter(set(chars_to_filter))\n",
    "\n",
    "filters = [filter_1, filter_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pe_triple_iterator = parallel_iterator(SRC_FILE, MT_FILE, PE_FILE)\n",
    "short_triples = [triple for triple in pe_triple_iterator if all(filter_f(triple) for filter_f in filters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# triple_cols = zip(*short_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detokenization logic\n",
    "MOSES_SCRIPTS = '/home/chris/projects/mosesdecoder/scripts/'\n",
    "detokenize_script = os.path.join(MOSES_SCRIPTS, 'tokenizer/detokenizer.perl')\n",
    "def detokenize(text, lang):\n",
    "    detokenizer_cmd = [detokenize_script, '-l', lang, '-q', '-']\n",
    "\n",
    "    if type(text) is unicode:\n",
    "        text = text.encode('utf8')\n",
    "\n",
    "    detokenizer = Popen(detokenizer_cmd, stdin=PIPE, stdout=PIPE)\n",
    "    text, _ = detokenizer.communicate(text)\n",
    "\n",
    "    utf_line = text.rstrip().decode('utf8')\n",
    "    return utf_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.src.0\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.mt.0\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.pe.0\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.src.1\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.mt.1\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.pe.1\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.src.2\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.mt.2\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.pe.2\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.src.3\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.mt.3\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.pe.3\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.src.4\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.mt.4\n",
      "Wrote 12 lines to /home/chris/projects/handycat/app/data/word_level_qe_experiments/experiment_data/test.pe.4\n"
     ]
    }
   ],
   "source": [
    "def write_lines(filename, lines, cutoff=None):\n",
    "    with codecs.open(filename, 'w', encoding='utf8') as out:\n",
    "        if cutoff == None:\n",
    "            cutoff = len(lines)\n",
    "        for i, l in enumerate(lines):\n",
    "            if i > cutoff:\n",
    "                break\n",
    "            # don't append newline to last line\n",
    "            if i == cutoff - 1:\n",
    "                out.write(u'{}'.format(l))\n",
    "            else:\n",
    "                out.write(u'{}\\n'.format(l))\n",
    "\n",
    "    print('Wrote {} lines to {}'.format(i+1, filename))\n",
    "\n",
    "output_files = [[os.path.join(OUTPUT_DIR, f_name + '.' + str(p_i))\n",
    "                for f_name in ['test.src', 'test.mt', 'test.pe']] for p_i in range(NUM_PROJECTS)]\n",
    "\n",
    "project_start_idx = 0\n",
    "for project_files in output_files:\n",
    "    project_end_idx = project_start_idx + SEGMENTS_PER_PROJECT\n",
    "    assert project_end_idx < len(short_triples), 'We cannot have duplicate segments, number of projects is too big'\n",
    "    # grab the right number of instances from triple_cols\n",
    "    output_triple_cols = zip(*short_triples[project_start_idx:project_end_idx])\n",
    "    project_start_idx = project_end_idx\n",
    "    \n",
    "    # we detokenize so that strings render correctly in the UI\n",
    "    src_rows, mt_rows, pe_rows = output_triple_cols\n",
    "    src_rows = [detokenize(row, SRC_LANG) for row in src_rows]\n",
    "    mt_rows = [detokenize(row, TRG_LANG) for row in mt_rows]\n",
    "    pe_rows = [detokenize(row, TRG_LANG) for row in pe_rows]\n",
    "\n",
    "    src_filename, mt_filename, pe_filename = project_files\n",
    "    \n",
    "    write_lines(src_filename, src_rows, cutoff=None)\n",
    "    write_lines(mt_filename, mt_rows, cutoff=None)\n",
    "    write_lines(pe_filename, pe_rows, cutoff=None)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(t[0], t[2]) for t in short_triples[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump a 20-sentence sample set for testing\n",
    "# remember we're going to use the WMT hyps as MT hyps, we'll use a single good APE system with constrained decoding to provide outputs\n",
    "# remember the APE server will need (at least) source + MT as inputs to work\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
